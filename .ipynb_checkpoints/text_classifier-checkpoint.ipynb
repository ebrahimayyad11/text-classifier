{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8b7157-5d5b-45fa-b030-93ed88c0fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307ee2c-c8fa-44dd-ba9d-f9723170006a",
   "metadata": {},
   "source": [
    "## Text reading line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2793f210-391c-42fd-9f21-98979dbb6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp':   'data/sentiment_analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'data/sentiment_analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'data/sentiment_analysis/imdb_labelled.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef4c4da-cefc-4435-8ff7-411859200c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'review'], sep='\\t')\n",
    "    df['source']=source\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595e71f1-5714-430b-b1bf-3cf845f56cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>review</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  review source\n",
       "0                           Wow... Loved this place.       1   yelp\n",
       "1                                 Crust is not good.       0   yelp\n",
       "2          Not tasty and the texture was just nasty.       0   yelp\n",
       "3  Stopped by during the late May bank holiday of...       1   yelp\n",
       "4  The selection on the menu was great and so wer...       1   yelp"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d808b00-6942-4d64-aca7-b5f227cb5a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    The selection on the menu was great and so wer...\n",
       "review                                                      1\n",
       "source                                                   yelp\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbb24a-74e2-438c-9402-c61a755bb69b",
   "metadata": {},
   "source": [
    "## Sklearn for reading sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c01aac4-4e8b-439a-a6e8-41b04e70e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac1b380-7428-4b61-be0b-dff2c11637cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d323d1f2-25bd-4c77-8355-1683107e634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56b21b-7ab5-49d7-b8aa-b26d345fee13",
   "metadata": {},
   "source": [
    "### Note : vectorizer take each word and put in dectionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a25ba0d-42f7-417f-85e4-7a73381d5b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04829449-483d-48f3-a8c6-19bc6088bacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= ['hello world John and no one','cream with chocolate']\n",
    "vectorizer.transform(test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b9b474-a416-4f85-a8b0-8d9e44caf2c3",
   "metadata": {},
   "source": [
    "### Note:: transform() >> toarray() --> return 1 if find the word inside transform , or 0 if not then store it to an array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca55815-7035-41f3-8b45-e629024937ff",
   "metadata": {},
   "source": [
    "## Defining a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abe260b2-9678-484b-b72d-a708253ce84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c58d96be-beff-4c4f-bf0d-c81f6685988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = df[df['source'] == 'yelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1db8703-81e1-4658-8e49-d469d189eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_yelp['sentence'].values\n",
    "review = df_yelp['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa73b226-eb62-4725-8c0d-e4670fa6faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, review, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81ea343-8358-48d9-b114-21be2eb7a2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x1714 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7368 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6acaaf-6119-4795-8911-f2c5364df6da",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5e9cd8-7fc8-4666-8515-34014b54df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83018ed9-f80a-4492-817d-6a172b32e85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f56a3b65-026d-4733-92f8-acbd10a62b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for yelp data: 0.7960\n",
      "Accuracy for amazon data: 0.7960\n",
      "Accuracy for imdb data: 0.7487\n"
     ]
    }
   ],
   "source": [
    "for source in df['source'].unique():\n",
    "    df_source = df[df['source'] == source]\n",
    "    sentences = df_source['sentence'].values\n",
    "    y = df_source['review'].values\n",
    "\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "        sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(sentences_train)\n",
    "    X_train = vectorizer.transform(sentences_train)\n",
    "    X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    print('Accuracy for {} data: {:.4f}'.format(source, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9482f437-5d25-445e-a670-30ada9fc914a",
   "metadata": {},
   "source": [
    "### Note:: use unique() to take only unique value without repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4119c58e-d2a3-479a-a276-4c5bde3a39ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
